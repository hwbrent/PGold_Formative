<!DOCTYPE html>
<html lang="en">
    <head>
        <title>AI in Healthcare</title>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/css/bootstrap.min.css">
    </head>
    <body>
        
        <div class="jumbotron text-center">
            <h1>Artificial Intelligence in Healthcare</h1> 
        <table>
            <tr>
                <th><form action="generalPage.html" target="_blank" class="col-sm-5">
                    <input type="submit" value="Homepage"/>
                </form>
                <th>
                <th><form action="p1.html" target="_blank" class="col-sm-5">
                    <input type="submit" value="Transportation"/>
                </form>
                <th>
                <th><form action="p2.html" target="_blank" class="col-sm-5">
                    <input type="submit" value="Healthcare"/>
                </form>
                <th>
                <th><form action="p3.html" target="_blank" class="col-sm-5">
                    <input type="submit" value="Page 3"/>
                </form>
                <th>
            </tr>
        </table>
            
        </div>

        <h2>Overview</h2>
        <p></p>
        <p>AI is being used or trialled for a range of healthcare and research purposes, including detection of disease, management of chronic conditions, delivery of health services, and drug discovery.  
            It has the potential to help address important health challenges, but might be limited by the quality of available health data, and by the inability of AI to display some human characteristics.
        </p>
        <h3>Current Research</h3>
        <p></p>
        <p>Various specialties in medicine have shown an increase in research regarding AI.
            As coronavirus continues to distribute, the United States is estimated to invest more than $2 billion in AI related healthcare research over the next 5 years, more than 4 times the amount spent in 2019 ($463 million). 
            Major technology companies - including Google, Microsoft, and IBM - are investing in the development of AI for healthcare and research.
            The number of AI start-up companies has also been steadily increasing.
            There are several UK-based companies, some of which have been set up in collaboration with UK universities and hospitals. Partnerships have been formed between NHS providers and AI developers such as IBM, DeepMind, Babylon Health, and Ultromics. 
        </p>
        <h4>Psychiatry</h4>
        <p></p>
        <p>In psychiatry, AI applications are still in a phase of proof-of-concept.
            Areas where the evidence is widening quickly include chatbots, conversational agents that imitate human behaviour and which have been studied for anxiety and depression.</p>
        

        <h3>Diagnosing Diseases</h3>
        <p></p>
        <p>Machine Learning is particularly helpful in areas where the diagnostic information a doctor examines is already digitized. Such as:</p>

        <ul>
        <li>Detecting lung cancer or strokes based on CT scans</li>
        <li>Assessing the risk of sudden cardiac death or other heart diseases based on electrocardiograms and cardiac MRI images</li>
        <li>Classifying skin lesions in skin images</li>
        <li>Finding indicators of diabetic retinopathy in eye images</li>
        </ul>
        
        <p>For example, in the autumn of 2018, researchers at Seoul National University Hospital and College of Medicine developed an AI algorithm called DLAD 
            (Deep Learning based Automatic Detection) to analyse chest radiographs and detect abnormal cell growth, such as potential cancers (Figure 2).
            The algorithm’s performance was compared to multiple physicians’ detection abilities on the same images and outperformed 17 of 18 doctors.</p>
        <a href="http://sitn.hms.harvard.edu/flash/2019/artificial-intelligence-in-medicine-applications-implications-and-limitations/" target="_blank">
            <img src="aimed.jpg" alt="Tumor Detection" style="width:400px;height:200px;">
        </a>
    
        <p>The left panel shows the image fed into an algorithm. The right panel shows a region of potentially dangerous cells, as identified by an algorithm, that a physician should look at more closely.</p>

        <h3>Implications</h3>
        <p></p>
        <p>The use of AI is predicted to decrease medical costs as there will be more accuracy in diagnosis and better predictions in the treatment plan as well as more prevention of disease.
            Other future uses for AI include Brain-computer Interfaces (BCI) which are predicted to help those with trouble moving, speaking or with a spinal cord injury.
            The BCIs will use AI to help these patients move and communicate by decoding neural activates.</p>
        <h3>Ethics</h3>
        <p></p>
        <h4>Data Collection</h4>
        <p></p>
        <p>In order to effectively train Machine Learning and use AI in healthcare, massive amounts of data must be gathered.
            Acquiring this data, however, comes at the cost of patient privacy in most cases and is not well received publicly.
            For example, a survey conducted in the UK estimated that 63% of the population is uncomfortable with sharing their personal data in order to improve artificial intelligence technology.
            The scarcity of real, accessible patient data is a hindrance that deters the progress of developing and deploying more artificial intelligence in healthcare.
        </p>
        <h4>Reliability and Safety</h4>
        <p></p>
        <p>Reliability and safety are key issues where AI is used to control equipment, deliver treatment, or make decisions in healthcare.
            AI could make errors and, if an error is difficult to detect or has knock-on effects, this could have serious implications.
            For example, in a 2015 clinical trial, an AI app was used to predict which patients were likely to develop complications following pneumonia, and therefore should be hospitalised.
            This app erroneously instructed doctors to send home patients with asthma due to its inability to take contextual information into account.
        </p>
        <h4>Data Bias</h4>
        <p></p>
        <p>Although AI applications have the potential to reduce human bias and error, they can also reflect and reinforce biases in the data used to train them.
            Concerns have been raised about the potential of AI to lead to discrimination in ways that may be hidden or which may not align with legally protected characteristics, such as gender, ethnicity, disability, and age.
            The House of Lords Select Committee on AI has cautioned that datasets used to train AI systems are often poorly representative of the wider population and, as a result, could make unfair decisions that reflect wider prejudices in society. The Committee also found that biases can be embedded in the algorithms themselves, reflecting the beliefs and prejudices of AI developers.
            Several commentators have called for increased diversity among developers to help address this issue.
        </p>
        <p>The benefits of AI in healthcare might not be evenly distributed. AI might work less well where data are scarce or more difficult to collect or render digitally.
            This could affect people with rare medical conditions, or others who are underrepresented in clinical trials and research data, such as Black, Asian, and minority ethnic populations.
        </p>
    
    </body>  
</html>
